---
title: Visualizing and sonifying how an artificial ear hears music
booktitle: Proceedings of the NeurIPS 2019 Competition and Demonstration Track
year: '2020'
abstract: " A system is presented that visualizes and sonifies the inner workings
  of a sound processing neural network in real-time. The models that are employed
  have been trained on music datasets in a self-supervised way using contrastive predictive
  coding.  An optimization procedure generates sounds that activate certain regions
  in the network.  That way it can be rendered audible how music sounds to this artificial
  ear.  In addition, the activations of the neurons at each point in time are visualized.
  \ For this, a force graph layout technique is used to create a vivid and dynamic
  representation of the neural network in action."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: herrmann20a
month: 0
tex_title: Visualizing and sonifying how an artificial ear hears music
firstpage: 192
lastpage: 202
page: 192-202
order: 192
cycles: false
bibtex_author: Herrmann, Vincent
author:
- given: Vincent
  family: Herrmann
date: 2020-08-19
address: 
container-title: Proceedings of the NeurIPS 2019 Competition and Demonstration Track
volume: '123'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 19
pdf: http://proceedings.mlr.press/v123/herrmann20a/herrmann20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
